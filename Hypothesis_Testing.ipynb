{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing Assignment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) A F&B manager wants to determine whether there is any significant difference in the diameter of the cutlet between two units. A randomly selected sample of cutlets was collected from both units and measured? Analyze the data and draw inferences at 5% significance level. Please state the assumptions and tests that you carried out to check validity of the assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unit A</th>\n",
       "      <th>Unit B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8090</td>\n",
       "      <td>6.7703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.4376</td>\n",
       "      <td>7.5093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.9157</td>\n",
       "      <td>6.7300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.3012</td>\n",
       "      <td>6.7878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4488</td>\n",
       "      <td>7.1522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.3871</td>\n",
       "      <td>6.8110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.8755</td>\n",
       "      <td>7.2212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0621</td>\n",
       "      <td>6.6606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.6840</td>\n",
       "      <td>7.2402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.8236</td>\n",
       "      <td>7.0503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.3930</td>\n",
       "      <td>6.8810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.5169</td>\n",
       "      <td>7.4059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.9246</td>\n",
       "      <td>6.7652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.9256</td>\n",
       "      <td>6.0380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.5797</td>\n",
       "      <td>7.1581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.8394</td>\n",
       "      <td>7.0240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.5970</td>\n",
       "      <td>6.6672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7.2705</td>\n",
       "      <td>7.4314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.2828</td>\n",
       "      <td>7.3070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.3495</td>\n",
       "      <td>6.7478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.9438</td>\n",
       "      <td>6.8889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7.1560</td>\n",
       "      <td>7.4220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.5341</td>\n",
       "      <td>6.5217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7.2854</td>\n",
       "      <td>7.1688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.9952</td>\n",
       "      <td>6.7594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.8568</td>\n",
       "      <td>6.9399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7.2163</td>\n",
       "      <td>7.0133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6.6801</td>\n",
       "      <td>6.9182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.9431</td>\n",
       "      <td>6.3346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7.0852</td>\n",
       "      <td>7.5459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6.7794</td>\n",
       "      <td>7.0992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7.2783</td>\n",
       "      <td>7.1180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>7.1561</td>\n",
       "      <td>6.6965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7.3943</td>\n",
       "      <td>6.5780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6.9405</td>\n",
       "      <td>7.3875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unit A  Unit B\n",
       "0   6.8090  6.7703\n",
       "1   6.4376  7.5093\n",
       "2   6.9157  6.7300\n",
       "3   7.3012  6.7878\n",
       "4   7.4488  7.1522\n",
       "5   7.3871  6.8110\n",
       "6   6.8755  7.2212\n",
       "7   7.0621  6.6606\n",
       "8   6.6840  7.2402\n",
       "9   6.8236  7.0503\n",
       "10  7.3930  6.8810\n",
       "11  7.5169  7.4059\n",
       "12  6.9246  6.7652\n",
       "13  6.9256  6.0380\n",
       "14  6.5797  7.1581\n",
       "15  6.8394  7.0240\n",
       "16  6.5970  6.6672\n",
       "17  7.2705  7.4314\n",
       "18  7.2828  7.3070\n",
       "19  7.3495  6.7478\n",
       "20  6.9438  6.8889\n",
       "21  7.1560  7.4220\n",
       "22  6.5341  6.5217\n",
       "23  7.2854  7.1688\n",
       "24  6.9952  6.7594\n",
       "25  6.8568  6.9399\n",
       "26  7.2163  7.0133\n",
       "27  6.6801  6.9182\n",
       "28  6.9431  6.3346\n",
       "29  7.0852  7.5459\n",
       "30  6.7794  7.0992\n",
       "31  7.2783  7.1180\n",
       "32  7.1561  6.6965\n",
       "33  7.3943  6.5780\n",
       "34  6.9405  7.3875"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutlets = pd.read_csv(\"C:\\\\Users\\\\User\\\\Documents\\\\Datascience_Assignments\\\\Assignment 3\\\\Cutlets.csv\")\n",
    "cutlets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume Null hypothesis as Ho: μ1 = μ2\n",
    "\n",
    "There is no difference in diameters of cutlets between two units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume Alternate hypothesis as Ha: μ1 ≠ μ2 \n",
    "\n",
    "There is significant difference in diameters of cutlets between two units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unitA = pd.Series(cutlets.iloc[:,0])\n",
    "unitB = pd.Series(cutlets.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47223947245995745"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value = sm.stats.ttest_ind(unitA,unitB)\n",
    "p_value[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given, α = 0.05.\n",
    "\n",
    "Clearly (p_value=0.4722) > (α = 0.05). \n",
    "Accept Null Hypothesis, μ1 = μ2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)    A hospital wants to determine whether there is any difference in the average Turn Around Time (TAT) of reports of the laboratories on their preferred list. They collected a random sample and recorded TAT for reports of 4 laboratories. TAT is defined as sample collected to report dispatch. Analyze the data and determine whether there is any difference in average TAT among the different laboratories at 5% significance level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laboratory 1</th>\n",
       "      <th>Laboratory 2</th>\n",
       "      <th>Laboratory 3</th>\n",
       "      <th>Laboratory 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>185.35</td>\n",
       "      <td>165.53</td>\n",
       "      <td>176.70</td>\n",
       "      <td>166.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170.49</td>\n",
       "      <td>185.91</td>\n",
       "      <td>198.45</td>\n",
       "      <td>160.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192.77</td>\n",
       "      <td>194.92</td>\n",
       "      <td>201.23</td>\n",
       "      <td>185.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>177.33</td>\n",
       "      <td>183.00</td>\n",
       "      <td>199.61</td>\n",
       "      <td>176.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>193.41</td>\n",
       "      <td>169.57</td>\n",
       "      <td>204.63</td>\n",
       "      <td>152.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>178.49</td>\n",
       "      <td>170.66</td>\n",
       "      <td>193.80</td>\n",
       "      <td>172.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>176.08</td>\n",
       "      <td>183.98</td>\n",
       "      <td>215.25</td>\n",
       "      <td>177.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>202.48</td>\n",
       "      <td>174.54</td>\n",
       "      <td>203.99</td>\n",
       "      <td>170.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>182.40</td>\n",
       "      <td>197.18</td>\n",
       "      <td>194.52</td>\n",
       "      <td>150.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>182.09</td>\n",
       "      <td>215.17</td>\n",
       "      <td>221.49</td>\n",
       "      <td>162.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Laboratory 1  Laboratory 2  Laboratory 3  Laboratory 4\n",
       "0          185.35        165.53        176.70        166.13\n",
       "1          170.49        185.91        198.45        160.79\n",
       "2          192.77        194.92        201.23        185.18\n",
       "3          177.33        183.00        199.61        176.42\n",
       "4          193.41        169.57        204.63        152.60\n",
       "..            ...           ...           ...           ...\n",
       "115        178.49        170.66        193.80        172.68\n",
       "116        176.08        183.98        215.25        177.64\n",
       "117        202.48        174.54        203.99        170.27\n",
       "118        182.40        197.18        194.52        150.87\n",
       "119        182.09        215.17        221.49        162.21\n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tat = pd.read_csv(\"C:\\\\Users\\\\User\\\\Documents\\\\Datascience_Assignments\\\\Assignment 3\\\\LabTAT.csv\")\n",
    "tat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have nothing to compare against each other. \n",
    "# We use Anova ftest statistics for analysis of varaince containing more than 2 samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume Null Hypothesis Ho as No Variance: All samples TAT population means are same.\n",
    "\n",
    "Assume Alternate Hypothesis Ha as It has Variance: Atleast one sample TAT population mean is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab1 = tat.iloc[:,0]\n",
    "lab2 = tat.iloc[:,1]\n",
    "lab3 = tat.iloc[:,2]\n",
    "lab4 = tat.iloc[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=118.70421654401437, pvalue=2.1156708949992414e-57)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value = stats.f_oneway(lab1,lab2,lab3,lab4)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given, α = 0.05.\n",
    "\n",
    "Clearly (p_value ~ 0) < (α = 0.05).\n",
    "\n",
    "Reject Null Hypothesis or Accept Alternate Hypothesis. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Sales of products in four different regions is tabulated for males and females. Find if male-female buyer rations are similar across regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](hypo_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume Null Hypothesis as Ho: Male-Female buyer rations are similar across regions.\n",
    "\n",
    "Assume Alternate Hypothesis as Ha: Male-Female buyer rations are dissimilar across regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  50,  142,  131,   70],\n",
       "       [ 435, 1523, 1356,  750]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buyer = np.array([[50,142,131,70],[435,1523,1356,750]])\n",
    "buyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6603094907091882"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chi2_contingency(buyer)\n",
    "result[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly (p_value = 0.6603) > (α = 0.05).\n",
    "\n",
    "Accept the Null Hypothesis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) TeleCall uses 4 centers around the globe to process customer order forms. They audit a certain %  of the customer order forms. Any error in order form renders it defective and has to be reworked before processing.  The manager wants to check whether the defective %  varies by centre. Please analyze the data at 5% significance level and help the manager draw appropriate inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume Null Hypothesis as Ho: Customer order forms defective % does not varies by centre. \n",
    "\n",
    "Assume Alternative hypothesis as Ha: Customer order forms defective % varies by centre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phillippines</th>\n",
       "      <th>Indonesia</th>\n",
       "      <th>Malta</th>\n",
       "      <th>India</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Error Free</td>\n",
       "      <td>Error Free</td>\n",
       "      <td>Defective</td>\n",
       "      <td>Error Free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Error Free</td>\n",
       "      <td>Error Free</td>\n",
       "      <td>Error Free</td>\n",
       "      <td>Defective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Error Free</td>\n",
       "      <td>Defective</td>\n",
       "      <td>Defective</td>\n",
       "      <td>Error Free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Error Free</td>\n",
       "      <td>Error Free</td>\n",
       "      <td>Error Free</td>\n",
       "      <td>Error Free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Error Free</td>\n",
       "      <td>Error Free</td>\n",
       "      <td>Defective</td>\n",
       "      <td>Error Free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Error Free</td>\n",
       "      <td>Error Free</td>\n",
       "      <td>Error Free</td>\n",
       "      <td>Error Free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Error Free</td>\n",
       "      <td>Error Free</td>\n",
       "      <td>Error Free</td>\n",
       "      <td>Error Free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Error Free</td>\n",
       "      <td>Error Free</td>\n",
       "      <td>Defective</td>\n",
       "      <td>Error Free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Error Free</td>\n",
       "      <td>Error Free</td>\n",
       "      <td>Error Free</td>\n",
       "      <td>Error Free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Error Free</td>\n",
       "      <td>Defective</td>\n",
       "      <td>Defective</td>\n",
       "      <td>Error Free</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Phillippines   Indonesia       Malta       India\n",
       "0     Error Free  Error Free   Defective  Error Free\n",
       "1     Error Free  Error Free  Error Free   Defective\n",
       "2     Error Free   Defective   Defective  Error Free\n",
       "3     Error Free  Error Free  Error Free  Error Free\n",
       "4     Error Free  Error Free   Defective  Error Free\n",
       "..           ...         ...         ...         ...\n",
       "295   Error Free  Error Free  Error Free  Error Free\n",
       "296   Error Free  Error Free  Error Free  Error Free\n",
       "297   Error Free  Error Free   Defective  Error Free\n",
       "298   Error Free  Error Free  Error Free  Error Free\n",
       "299   Error Free   Defective   Defective  Error Free\n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer = pd.read_csv(\"C:\\\\Users\\\\User\\\\Documents\\\\Datascience_Assignments\\\\Assignment 3\\\\Costomer+OrderForm.csv\")\n",
    "customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Error Free    271\n",
       "Defective      29\n",
       "Name: Phillippines, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer.Phillippines.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Error Free    267\n",
       "Defective      33\n",
       "Name: Indonesia, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer.Indonesia.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Error Free    269\n",
       "Defective      31\n",
       "Name: Malta, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer.Malta.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Error Free    280\n",
       "Defective      20\n",
       "Name: India, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer.India.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[271, 267, 269, 280],\n",
       "       [ 29,  33,  31,  20]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = np.array([[271,267,269,280],[29,33,31,20]])\n",
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2771020991233135"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chi2_contingency(order)\n",
    "result[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly (p_value = 0.2771) > (α = 0.05). \n",
    "\n",
    "Accept Null Hypothesis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
